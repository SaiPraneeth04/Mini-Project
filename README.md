## GESTURE Control Using Open CV Python:

The development of a hand gesture recognition system for controlling brightness and volume levels in smart environments aims to enhance user interaction by providing a seamless and intuitive method for managing device settings. 

This project focuses on leveraging real-time hand tracking technology to enable users to adjust lighting and sound levels through natural gestures, thereby improving accessibility and convenience in smart homes and office spaces.

## About:

The Hand Gesture Recognition System for Smart Environment Control is a project designed to implement a real-time hand tracking solution that allows users to manage brightness and volume levels through intuitive gestures. 

Traditional methods of adjusting these settings often require physical interaction with devices or remote controls, which can be inconvenient and less accessible. 

This project aims to streamline the user experience by providing a hands-free interface that recognizes specific hand movements to adjust lighting and sound, enhancing accessibility and convenience in smart homes and office spaces. By utilizing advanced computer vision techniques, this system promotes a more interactive and responsive environment for users.

## Features:
```
-Utilizes real-time hand gesture recognition for intuitive control.
-Integrates with existing smart devices for seamless interaction.
-High accuracy in gesture detection and distance measurement.
-Supports multiple gestures for brightness adjustment, volume control, and zoom functionalities.
-Provides a user-friendly interface that enhances accessibility and convenience.
-Lightweight and efficient, allowing for smooth performance on standard hardware.
-Adjustable parameters for sensitivity and responsiveness based on user preferences.
```
## Requirements
```
Hardware Requirements:
  -Processor: Intel i5 or equivalent (minimum).
  -RAM: 8 GB or higher.
  -Webcam: Functional webcam for hand gesture detection.
  -Graphics Card: Optional but recommended for improved processing speed (NVIDIA GPU for CUDA support).
Software Requirements:
  -Operating System: Windows 10 or higher, Linux, or macOS.
  -Python: Version 3.6 or higher.
  Libraries:
    -OpenCV: For video capture and image processing.
    -NumPy: For numerical operations and array manipulations.
    -Mediapipe: For hand tracking and gesture recognition.
    -Screen Brightness Control: For adjusting screen brightness.
    -PyAutoGUI: For simulating keyboard shortcuts.
    -Pycaw: For audio control on Windows.
    -Matplotlib: For plotting live graphs.
```
## System Architecture

![flow diagram](https://github.com/user-attachments/assets/b3a6d074-9bd0-4ee0-b36e-56db2a06fa2b)


## Output

<!--Embed the Output picture at respective places as shown below as shown below-->
#### Output1 - Volume control

##### Volume Increase:

![Screenshot 2024-10-28 212442](https://github.com/user-attachments/assets/e149eaf9-f1f0-4922-a6ad-925e5d479c2d)


##### Volume Decrease:

![Screenshot 2024-10-28 212317](https://github.com/user-attachments/assets/6376c9d8-29cc-4460-91a8-fe3b0ba34503)


#### Output2 - Brightness Control:

  ##### Brightness Increase:
  
![Screenshot 2024-10-26 235335](https://github.com/user-attachments/assets/6ff0168d-033b-46d5-a5c5-7d2b20b93ada)

  ##### Brightness Decrease:
  
![Screenshot 2024-10-26 235559](https://github.com/user-attachments/assets/41a48e1a-5e4d-4b93-a278-f02ad42f5371)

#### Output3 - Zoom Coltrol
   ##### Zoom Out:

![Screenshot 2024-10-28 211959](https://github.com/user-attachments/assets/48eb3713-3752-4fa9-97ac-9c03c1ba1f17)


   ##### Zoon In:

   ![Screenshot 2024-10-28 212137](https://github.com/user-attachments/assets/8f4b264b-8aa3-46f9-91f6-563a2fdb5809)


## Results and Impact
The Hand Gesture Recognition System for controlling brightness, volume, and zoom provides a novel and intuitive interface for users, particularly benefiting those with mobility challenges or impairments.

By leveraging computer vision and machine learning techniques, the project facilitates hands-free operation of devices, enhancing user convenience and accessibility.

This system not only showcases the practical applications of gesture recognition technology but also sets the stage for further innovations in human-computer interaction. 

The project's success underscores the importance of creating adaptive technologies that empower users, contributing to a more inclusive and user-friendly digital landscape.

![collage](https://github.com/user-attachments/assets/7575ea44-ae66-4d0c-b24c-84849dbba061)


## Articles published / References
1. Zhou, Y., Wang, Y., & Zhang, H. (2019). Gesture Recognition Based on Hand Tracking for Human-Computer Interaction. International Journal of Computer Applications, 178(6)DOI: 10.5120/ijca2019919079

2. Gupta, A., & Jain, R. (2020). A Survey on Hand Gesture Recognition Techniques for Human-Computer Interaction. Journal of Visual Communication and Image . Representation, 67, 102795.DOI: 10.1016/j.jvcir.2020.102795

3. Khan, M. A., & Ahmed, I. (2021). Hand Gesture Recognition Techniques: A Review. Journal of Ambient Intelligence and Humanized Computing, 12(3), 3567-3593.DOI: 10.1007/s12652-020-02564-5




